/app/src/fsfm-3c/util/misc.py:259: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()
/usr/local/lib/python3.9/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/app/src/fsfm-3c/pretrain/engine_pretrain.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/usr/local/lib/python3.9/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
/app/src/fsfm-3c/pretrain/engine_pretrain.py:95: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Traceback (most recent call last):
  File "/app/src/fsfm-3c/pretrain/main_pretrain.py", line 381, in <module>
    main(args)
  File "/app/src/fsfm-3c/pretrain/main_pretrain.py", line 319, in main
    train_stats = train_one_epoch(model_without_ddp,
  File "/app/src/fsfm-3c/pretrain/engine_pretrain.py", line 150, in train_one_epoch
    torch.cuda.synchronize()
  File "/usr/local/lib/python3.9/site-packages/torch/cuda/__init__.py", line 952, in synchronize
    _lazy_init()
  File "/usr/local/lib/python3.9/site-packages/torch/cuda/__init__.py", line 310, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
